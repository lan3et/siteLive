SiteLive-python3.6

## 功能
***

针对挖掘SRC过程中收集资产后得到的大量子域名、ip识别筛选过程较慢的问题进行解决，通过异步请求对访问不存在目录及根目录状态码及返回内容的hash作比较使用协程批量判断网站是否存活并获取网站title

#### 版本更新：
***

由于python的多线程的问题：GIL导致PYTHON 无法使用到计算机的多核，仅能使用单核，

改为使用aiohttp协程处理IO密集型的问题，加快效率

#### 代码逻辑
***

+ 200：这里的状态码处理是个很麻烦的问题，之前和某个SRC的小伙伴聊过，因为很多大型互联网企业不愿意因为安全而影响业务（尤其是电商金融类公司），很多大型互联网公司的网站的WAF采取对全部返回包都返回200的处理，所以通过状态码去判断网站是否存活会出现很多误报情况，之后想到设置多个不存在网页链接让脚本去访问并计算hash进行对比（目前脚本采取的是这样的方式），但是在实战中发现对```/XXXXX 网页不存在```这种返回值和不存在链接存在直接关联的网站误报率很高，所以接下来考虑使用文本相似度计算，使用类似汉明距离算法来访问计算两个网页间的距离，对网页进行进一步的判断

+ 30X：这里采用对HTTP包中头部Location字段继续进行请求并判断返回包的方式对网站是否存活进行判断，由于在实战中发现有些站点去请求Location字段的网址时会继续返回30X，并且在这个返回包中有时Location的值仍为之前第一个请求包的值而有些则为原链接废弃后服务器返回的另一个新站点的地址，所以这里对30X的站点第二次请求仍返回30X值的情况继续进行请求并判断返回值

+ 40X：这里设置的状态码较多，需要分开进行处理
	
	+ 400：对于返回400状态码的网站，如果原请求为HTTP，那么脚本会将请求协议更改为HTTPS并进行访问然后重新根据返回的状态码进行判断。同理 ，如果原请求为HTTPS，那么脚本会将请求协议更改为HTTP并进行访问然后重新根据返回的状态码进行判断。在两次访问都为400时将网站归类为可放弃的站点，在实际接触中，该类站点通常需要正确的协议+正确的目录+正确的文件名+正确的参数，才能返回正常的结果，其余访问皆为400，所以该站点FUZZ难度较大，非常考验字典强度和耐心，所以在这里选择放弃
	+ 401/415：这两类返回值一个需要正确的账号密码，一个往往是ajax传参的参数类型错误，都是需要提供正确的参数值或参数类型才能正常访问，而网站的功能是没有问题的，所以归类为较大几率存活的网站
	+ 404：需要访问根目录然后根据访问根目录的返回值再进行判断
	
+ 403/50X：对于50X状态码的网站，会直接判定为服务器异常导致的非正常站点，归类为应当放弃的站点，而返回403的网站在访问根目录仍为403时，说明需要提供的数据较多（正确的目录、参数、参数值等），往往为图片服务器，故归类为应当放弃的站点

#### 运行结果
***
live_site：正常的WEB网站
almost_live_site：存在WEB服务且大概率业务正常运行的网站
nearly_dead_site：几乎可放弃的网站
dead_site：WEB服务不存活的网站或利用门槛极高几乎无利用价值的网站
not_web_site：非WEB业务的地址

#### 备注
***
由于asyncio调用底层的select()，在linux服务器下最多只能有1024个线程，win下最多只有509个线程，线程数超过会报错，此处采用回调接口的方式解决，也可采取限制线程数<509来解决


